/**
 * MVP Audio-to-Diagram Pipeline
 * Minimal Viable Product implementation following custom instructions
 * ğŸ”„ Focus: å‹•ä½œã™ã‚‹æœ€å°å®Ÿè£… â†’ æ®µéšçš„æ”¹å–„
 */

import { BrowserTranscriber } from '@/transcription/browser-transcriber';
import { SimpleDiagramDetector, SimpleDiagramAnalysis } from '@/analysis/simple-diagram-detector';
import { SimpleLayoutEngine, LayoutResult } from '@/visualization/simple-layout-engine';

export interface MVPInput {
  audioFile: File;
  options?: {
    language?: string;
    diagramTypes?: string[];
    outputFormat?: 'json' | 'svg' | 'canvas';
  };
}

export interface MVPScene {
  id: string;
  startTime: number;
  endTime: number;
  content: string;
  diagramType: string;
  confidence: number;
  layout: LayoutResult;
  analysis: SimpleDiagramAnalysis;
}

export interface MVPResult {
  success: boolean;
  audioUrl?: string;
  transcript?: string;
  scenes: MVPScene[];
  processingTime: number;
  error?: string;
  metadata: {
    totalScenes: number;
    averageConfidence: number;
    processingSteps: string[];
  };
}

export type ProgressCallback = (step: string, progress: number) => void;

/**
 * Simple MVP Pipeline
 * ğŸ”„ Custom Instructions: å°ã•ãä½œã‚Šã€ç¢ºå®Ÿã«å‹•ä½œç¢ºèª
 */
export class MVPPipeline {
  private transcriber: BrowserTranscriber;
  private detector: SimpleDiagramDetector;
  private layoutEngine: SimpleLayoutEngine;
  private iteration: number = 0;

  constructor() {
    this.transcriber = new BrowserTranscriber();
    this.detector = new SimpleDiagramDetector();
    this.layoutEngine = new SimpleLayoutEngine({
      width: 1280,
      height: 720,
      nodeWidth: 140,
      nodeHeight: 70,
      spacing: 100,
      margin: 80
    });
  }

  /**
   * Process audio file through simple pipeline
   * ğŸ”„ Custom Instructions: å®Ÿè£…â†’ãƒ†ã‚¹ãƒˆâ†’è©•ä¾¡â†’æ”¹å–„
   */
  async process(input: MVPInput, onProgress?: ProgressCallback): Promise<MVPResult> {
    const startTime = Date.now();
    this.iteration++;
    const processingSteps: string[] = [];

    console.log(`ğŸš€ MVP Pipeline Iteration ${this.iteration} - Starting...`);

    try {
      // Step 1: Audio Processing (10-30%)
      onProgress?.('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...', 10);
      processingSteps.push('audio_processing');

      const audioUrl = URL.createObjectURL(input.audioFile);
      console.log(`ğŸ“ Audio file: ${input.audioFile.name} (${(input.audioFile.size / 1024 / 1024).toFixed(2)}MB)`);

      // Step 2: Transcription (30-50%)
      onProgress?.('éŸ³å£°ã‚’æ–‡å­—ã«å¤‰æ›ä¸­...', 30);
      processingSteps.push('transcription');

      const transcriptionResult = await this.transcriber.transcribeAudioFile(input.audioFile);

      if (!transcriptionResult.success || !transcriptionResult.segments) {
        throw new Error('Transcription failed');
      }

      const transcript = transcriptionResult.segments
        .map(seg => seg.text)
        .join(' ');

      console.log(`ğŸ“ Transcription completed: ${transcriptionResult.segments.length} segments`);

      // Step 3: Scene Analysis (50-70%)
      onProgress?.('ã‚·ãƒ¼ãƒ³ã‚’åˆ†æä¸­...', 50);
      processingSteps.push('scene_analysis');

      const scenes: MVPScene[] = [];

      for (let i = 0; i < transcriptionResult.segments.length; i++) {
        const segment = transcriptionResult.segments[i];

        onProgress?.(`ã‚·ãƒ¼ãƒ³ ${i + 1}/${transcriptionResult.segments.length} ã‚’åˆ†æä¸­...`,
          50 + (i / transcriptionResult.segments.length) * 20);

        // Convert segment format
        const textSegment = {
          text: segment.text,
          startMs: segment.start * 1000,
          endMs: segment.end * 1000,
          summary: segment.text.substring(0, 50) + '...'
        };

        // Detect diagram type
        const analysis = await this.detector.analyze(textSegment);

        // Generate layout
        const layout = await this.layoutEngine.generateLayout(
          analysis.nodes,
          analysis.edges,
          analysis.type
        );

        if (layout.success) {
          scenes.push({
            id: `scene-${i + 1}`,
            startTime: segment.start,
            endTime: segment.end,
            content: segment.text,
            diagramType: analysis.type,
            confidence: analysis.confidence,
            layout,
            analysis
          });
        }
      }

      console.log(`ğŸ“Š Scene analysis completed: ${scenes.length} scenes generated`);

      // Step 4: Quality Assessment (70-90%)
      onProgress?.('å“è³ªã‚’è©•ä¾¡ä¸­...', 70);
      processingSteps.push('quality_assessment');

      const averageConfidence = scenes.length > 0
        ? scenes.reduce((sum, scene) => sum + scene.confidence, 0) / scenes.length
        : 0;

      // Step 5: Results Preparation (90-100%)
      onProgress?.('çµæœã‚’æº–å‚™ä¸­...', 90);
      processingSteps.push('results_preparation');

      const processingTime = Date.now() - startTime;

      const result: MVPResult = {
        success: true,
        audioUrl,
        transcript,
        scenes,
        processingTime,
        metadata: {
          totalScenes: scenes.length,
          averageConfidence,
          processingSteps
        }
      };

      onProgress?.('å®Œäº†', 100);

      console.log(`âœ… MVP Pipeline completed in ${(processingTime / 1000).toFixed(1)}s`);
      console.log(`ğŸ“ˆ Quality metrics: ${scenes.length} scenes, ${(averageConfidence * 100).toFixed(1)}% confidence`);

      return result;

    } catch (error) {
      console.error('âŒ MVP Pipeline failed:', error);

      const processingTime = Date.now() - startTime;
      processingSteps.push('error_handling');

      return {
        success: false,
        scenes: [],
        processingTime,
        error: error instanceof Error ? error.message : 'Unknown error',
        metadata: {
          totalScenes: 0,
          averageConfidence: 0,
          processingSteps
        }
      };
    }
  }

  /**
   * Process with retry logic
   * ğŸ”„ Custom Instructions: ã‚¨ãƒ©ãƒ¼å›å¾©æˆ¦ç•¥
   */
  async processWithRetry(
    input: MVPInput,
    onProgress?: ProgressCallback,
    maxRetries: number = 2
  ): Promise<MVPResult> {
    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        onProgress?.(`è©¦è¡Œ ${attempt}/${maxRetries}`, 0);

        const result = await this.process(input, onProgress);

        if (result.success) {
          if (attempt > 1) {
            console.log(`âœ… MVP Pipeline succeeded on attempt ${attempt}`);
          }
          return result;
        }

        lastError = new Error(result.error || 'Processing failed');

      } catch (error) {
        lastError = error instanceof Error ? error : new Error('Unknown error');
        console.warn(`âš ï¸ MVP Pipeline attempt ${attempt} failed:`, lastError.message);

        if (attempt < maxRetries) {
          // Simple retry delay
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
      }
    }

    console.error(`âŒ All ${maxRetries} attempts failed`);

    return {
      success: false,
      scenes: [],
      processingTime: 0,
      error: `All ${maxRetries} attempts failed. Last error: ${lastError?.message}`,
      metadata: {
        totalScenes: 0,
        averageConfidence: 0,
        processingSteps: ['retry_failure']
      }
    };
  }

  /**
   * Generate demo with mock data
   * ğŸ”„ Custom Instructions: ãƒ‡ãƒ¢æ©Ÿèƒ½å¿…é ˆ
   */
  async generateDemo(onProgress?: ProgressCallback): Promise<MVPResult> {
    console.log('ğŸ¯ Generating MVP demo with mock data...');

    onProgress?.('ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...', 10);

    // Simulate processing time
    await new Promise(resolve => setTimeout(resolve, 500));

    onProgress?.('éŸ³å£°ã‚’åˆ†æä¸­...', 30);
    await new Promise(resolve => setTimeout(resolve, 800));

    onProgress?.('å›³è§£ã‚’ç”Ÿæˆä¸­...', 60);
    await new Promise(resolve => setTimeout(resolve, 1000));

    onProgress?.('ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æœ€é©åŒ–ä¸­...', 80);
    await new Promise(resolve => setTimeout(resolve, 600));

    // Generate mock scenes
    const mockScenes: MVPScene[] = [
      {
        id: 'demo-scene-1',
        startTime: 0,
        endTime: 8,
        content: 'ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹ã«ã¯é–‹å§‹ã€å‡¦ç†ã€åˆ¤æ–­ã€çµ‚äº†ãŒã‚ã‚Šã¾ã™ã€‚',
        diagramType: 'flow',
        confidence: 0.92,
        layout: {
          success: true,
          nodes: [
            { id: 'start', label: 'é–‹å§‹', x: 540, y: 100, width: 140, height: 70 },
            { id: 'process', label: 'å‡¦ç†', x: 540, y: 220, width: 140, height: 70 },
            { id: 'decision', label: 'åˆ¤æ–­', x: 540, y: 340, width: 140, height: 70 },
            { id: 'end', label: 'çµ‚äº†', x: 540, y: 460, width: 140, height: 70 }
          ],
          edges: [
            { id: 'e1', from: 'start', to: 'process', points: [{ x: 610, y: 170 }, { x: 610, y: 220 }] },
            { id: 'e2', from: 'process', to: 'decision', points: [{ x: 610, y: 290 }, { x: 610, y: 340 }] },
            { id: 'e3', from: 'decision', to: 'end', points: [{ x: 610, y: 410 }, { x: 610, y: 460 }] }
          ],
          width: 1280,
          height: 720
        },
        analysis: {
          type: 'flow',
          confidence: 0.92,
          nodes: [
            { id: 'start', label: 'é–‹å§‹' },
            { id: 'process', label: 'å‡¦ç†' },
            { id: 'decision', label: 'åˆ¤æ–­' },
            { id: 'end', label: 'çµ‚äº†' }
          ],
          edges: [
            { id: 'e1', from: 'start', to: 'process' },
            { id: 'e2', from: 'process', to: 'decision' },
            { id: 'e3', from: 'decision', to: 'end' }
          ],
          reasoning: 'ãƒ—ãƒ­ã‚»ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ / é †åºæ€§ã‚’ç¤ºã™èªå¥ãŒå«ã¾ã‚Œã¦ã„ã¾ã™'
        }
      },
      {
        id: 'demo-scene-2',
        startTime: 8,
        endTime: 16,
        content: 'çµ„ç¹”æ§‹é€ ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚éšå±¤ãŒã‚ã‚Šã€å„éƒ¨é–€ã«ãƒãƒ¼ãƒ ãŒé…ç½®ã•ã‚Œã¦ã„ã¾ã™ã€‚',
        diagramType: 'tree',
        confidence: 0.88,
        layout: {
          success: true,
          nodes: [
            { id: 'org', label: 'çµ„ç¹”', x: 540, y: 100, width: 140, height: 70 },
            { id: 'dept1', label: 'é–‹ç™ºéƒ¨', x: 440, y: 220, width: 140, height: 70 },
            { id: 'dept2', label: 'å–¶æ¥­éƒ¨', x: 640, y: 220, width: 140, height: 70 },
            { id: 'team1', label: 'ãƒãƒ¼ãƒ 1', x: 440, y: 340, width: 140, height: 70 }
          ],
          edges: [
            { id: 'e1', from: 'org', to: 'dept1', points: [{ x: 580, y: 170 }, { x: 510, y: 220 }] },
            { id: 'e2', from: 'org', to: 'dept2', points: [{ x: 620, y: 170 }, { x: 710, y: 220 }] },
            { id: 'e3', from: 'dept1', to: 'team1', points: [{ x: 510, y: 290 }, { x: 510, y: 340 }] }
          ],
          width: 1280,
          height: 720
        },
        analysis: {
          type: 'tree',
          confidence: 0.88,
          nodes: [
            { id: 'org', label: 'çµ„ç¹”' },
            { id: 'dept1', label: 'é–‹ç™ºéƒ¨' },
            { id: 'dept2', label: 'å–¶æ¥­éƒ¨' },
            { id: 'team1', label: 'ãƒãƒ¼ãƒ 1' }
          ],
          edges: [
            { id: 'e1', from: 'org', to: 'dept1' },
            { id: 'e2', from: 'org', to: 'dept2' },
            { id: 'e3', from: 'dept1', to: 'team1' }
          ],
          reasoning: 'éšå±¤æ§‹é€ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ / çµ„ç¹”ç”¨èªãŒå«ã¾ã‚Œã¦ã„ã¾ã™'
        }
      }
    ];

    onProgress?.('å®Œäº†', 100);

    const result: MVPResult = {
      success: true,
      audioUrl: 'demo://mock-audio',
      transcript: mockScenes.map(s => s.content).join(' '),
      scenes: mockScenes,
      processingTime: 2900,
      metadata: {
        totalScenes: mockScenes.length,
        averageConfidence: mockScenes.reduce((sum, s) => sum + s.confidence, 0) / mockScenes.length,
        processingSteps: ['demo_generation', 'mock_transcription', 'mock_analysis', 'mock_layout']
      }
    };

    console.log('âœ… MVP Demo completed');
    return result;
  }

  /**
   * Get pipeline capabilities
   */
  getCapabilities() {
    return {
      transcription: this.transcriber.getSupportedFeatures(),
      diagramDetection: this.detector.getCapabilities(),
      layoutGeneration: this.layoutEngine.getCapabilities(),
      pipeline: {
        maxRetries: 3,
        supportedFormats: ['mp3', 'wav', 'ogg', 'm4a'],
        maxFileSize: '50MB',
        supportedLanguages: ['ja', 'en'],
        iteration: this.iteration
      }
    };
  }

  /**
   * Run comprehensive test
   * ğŸ”„ Custom Instructions: ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½å†…è”µ
   */
  async runTest(): Promise<void> {
    console.log('ğŸ§ª Running MVP Pipeline comprehensive test...');

    // Test demo generation
    console.log('Testing demo generation...');
    const demoResult = await this.generateDemo();
    const demoSuccess = demoResult.success && demoResult.scenes.length > 0;
    console.log(`${demoSuccess ? 'âœ…' : 'âŒ'} Demo generation: ${demoResult.scenes.length} scenes`);

    // Test component capabilities
    console.log('Testing component capabilities...');
    await this.detector.testDetector();
    await this.layoutEngine.testLayoutEngine();

    // Test error handling
    console.log('Testing error handling...');
    try {
      // Create invalid input
      const invalidFile = new File([''], 'invalid.txt', { type: 'text/plain' });
      const errorResult = await this.process({ audioFile: invalidFile });
      console.log(`${errorResult.success ? 'âŒ' : 'âœ…'} Error handling: Properly handled invalid input`);
    } catch (error) {
      console.log(`âœ… Error handling: Exception caught properly`);
    }

    console.log('ğŸ§ª MVP Pipeline testing completed');
  }

  /**
   * Get current iteration number
   */
  getCurrentIteration(): number {
    return this.iteration;
  }
}

export const mvpPipeline = new MVPPipeline();